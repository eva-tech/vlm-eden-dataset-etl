# =============================================================================
# VLM Eden Dataset ETL - Environment Variables Template
# =============================================================================
# Copy this file to .env and fill in your actual values
# cp .env.dist .env

# =============================================================================
# Source Database Configuration
# =============================================================================
# PostgreSQL database containing PACS data (source)
SOURCE_DATABASE_NAME=postgres
SOURCE_DATABASE_USER=postgres-testing
SOURCE_DATABASE_PASS=your_source_database_password
SOURCE_DATABASE_HOST=your_source_database_host
SOURCE_DATABASE_PORT=5432

# DATABASE_USER=postgres
# DATABASE_NAME=postgres-testing
# DATABASE_PASS=your_source_database_password
# DATABASE_HOST=your_source_database_host

# =============================================================================
# Destination Database Configuration (Optional)
# =============================================================================
# PostgreSQL database for destination (if needed)
DESTINATION_DATABASE_NAME=your_destination_db
DESTINATION_DATABASE_USER=your_destination_user
DESTINATION_DATABASE_PASS=your_destination_password
DESTINATION_DATABASE_HOST=your_destination_host
DESTINATION_DATABASE_PORT=5432

# =============================================================================
# Redis Configuration
# =============================================================================
# Redis URL for Celery broker and result backend
REDIS_URL=redis://localhost:6379/0
BROKER_URL=redis://localhost:6379/0

# =============================================================================
# AWS S3 Origin Bucket Configuration
# =============================================================================
# Origin S3 bucket name (where files are copied from)
S3_ORIGIN_BUCKET_NAME=your_s3_origin_bucket_name

# AWS credentials for accessing S3 origin bucket
AWS_ACCESS_KEY_ID=YOUR_AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY=YOUR_AWS_SECRET_ACCESS_KEY
AWS_REGION_NAME=us-east-1

# =============================================================================
# Google Cloud Storage Destination Bucket Configuration
# =============================================================================
# Destination GCS bucket name (where files are copied to)
GCS_BUCKET_NAME=ai-training-dev

# Optional: Path to GCS service account JSON key file
# If not provided, uses Application Default Credentials (gcloud auth application-default login)
GCS_CREDENTIALS_PATH=/path/to/service-account-key.json

# =============================================================================
# Celery Configuration
# =============================================================================
# Celery uses REDIS_URL for broker and result backend

# =============================================================================
# Flower Configuration
# =============================================================================
# Flower dashboard authentication
FLOWER_USER=admin
FLOWER_PASSWORD=your_flower_password

# =============================================================================
# Application Configuration
# =============================================================================
# Secret key for application security
SECRET_KEY=your_secret_key_here

# Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOGGING_LEVEL=INFO

# =============================================================================
# Error Tracking (Optional)
# =============================================================================
# Sentry DSN for error tracking (optional)
SENTRY_DNS=your_sentry_dsn_here
